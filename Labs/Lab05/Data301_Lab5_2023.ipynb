{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKxPJxl8je70"
      },
      "source": [
        "#Part A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TGeU0g9r60l",
        "outputId": "b1d08446-2490-43b7-e91c-4b1e87595946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.4.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.4-cp310-cp310-linux_x86_64.whl size=3365683 sha256=68c02a876e113ddaee7dd9b16fcf73716d8b0a1c777a62d4fc645f2905c0e89b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/1b/b5/97ec4cfccdde26e0f3590ad6e09a5242d508dff09704ef86c1\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-3.1.4\n"
          ]
        }
      ],
      "source": [
        "!pip install mpi4py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdPdd3C_rjQ_"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZUOUPZOrtTB",
        "outputId": "cb0fa246-06ab-4bfa-93ed-04cd20b9cef0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing question-1-mpi.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile question-1-mpi.py\n",
        "\n",
        "import numpy\n",
        "from mpi4py import MPI\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "\n",
        "randNum = numpy.zeros(1)\n",
        "receivebuffer = numpy.zeros(1)\n",
        "randNum[0] = numpy.random.random_sample(1)\n",
        "\n",
        "if rank == 1:\n",
        "    print(\"Process 1 before receiving has the number\", randNum[0])\n",
        "    comm.Recv(receivebuffer, source=0)\n",
        "    print(\"Process 1 received the number\", receivebuffer[0])\n",
        "    bigger = max(randNum[0], receivebuffer[0])\n",
        "    print(\"Process 1 has max value \", bigger)\n",
        "    comm.Send(bigger, dest=0)\n",
        "\n",
        "if rank == 0:\n",
        "    print(\"Process 0 drew the number\", randNum[0])\n",
        "\n",
        "    comm.Send(randNum, dest=1)\n",
        "    comm.Recv(receivebuffer, source=1)\n",
        "    print(\"Process 0 has max value \", receivebuffer[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Q1, we expect the following cell output to be of the form:\n",
        "\n",
        "\n",
        "```\n",
        "Process 0 drew the number 0.0177029648837449\n",
        "Process 1 before receiving has the number 0.1308715233582639\n",
        "Process 1 received the number 0.0177029648837449\n",
        "Process 1 has max value 0.1308715233582639\n",
        "Process 0 has max value 0.1308715233582639\n",
        "```\n",
        "\n",
        "\n",
        "(but with different numbers)."
      ],
      "metadata": {
        "id": "2wPAeHW1qHpC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rfcPAJQrvuY",
        "outputId": "52861544-f64f-41df-c8ce-af9ade9d2e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 0 drew the number 0.6954409135449617\n",
            "Process 1 before receiving has the number 0.36124728405715756\n",
            "Process 1 received the number 0.6954409135449617\n",
            "Process 1 has max value  0.6954409135449617\n",
            "Process 0 has max value  0.6954409135449617\n"
          ]
        }
      ],
      "source": [
        "!mpiexec --allow-run-as-root --oversubscribe -n 2 python question-1-mpi.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UJ3b7F8rlxy"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jub3libsFPC",
        "outputId": "76dbf614-b173-4315-9206-4fb89dd7c221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing question-2-mpi.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile question-2-mpi.py\n",
        "\n",
        "import numpy\n",
        "from mpi4py import MPI\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "\n",
        "randNum = numpy.zeros(1)\n",
        "receivebuffer = numpy.zeros(1)\n",
        "\n",
        "if rank == 1:\n",
        "    print(\"Process 1 before receiving has the number\", randNum[0])\n",
        "    \n",
        "    randNum[0] = numpy.random.random_sample(1)\n",
        "    print(\"Process 1 after generating sample\", randNum[0])\n",
        "    comm.Irecv(receivebuffer, source=0).wait()\n",
        "    print(\"Process 1 received the number\", receivebuffer[0])\n",
        "\n",
        "    bigger = max(randNum[0], receivebuffer[0])\n",
        "    print(\"Process 1 has max value \", bigger)\n",
        "\n",
        "    comm.Isend(bigger, dest=0)\n",
        "\n",
        "if rank == 0:\n",
        "    randNum[0] = numpy.random.random_sample(1)\n",
        "    print(\"Process 0 drew the number\", randNum[0])\n",
        "\n",
        "    comm.Isend(randNum, dest=1)\n",
        "\n",
        "    comm.Irecv(receivebuffer, source=1).wait()\n",
        "    \n",
        "    print(\"Process 0 has max value \", receivebuffer[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Q2, we expect the following cell output to be in the form:\n",
        "\n",
        "```\n",
        "Process 1 before receiving has the number 0.0\n",
        "Process 0 drew the number 0.714475096728165\n",
        "Process 1 after generating sample 0.5177927276591507\n",
        "Process 1 received the number 0.714475096728165\n",
        "Process 1 has max value 0.714475096728165\n",
        "Process 0 has max value 0.714475096728165\n",
        "```\n",
        "(but, again, with different numbers).\n"
      ],
      "metadata": {
        "id": "iY0puj0Xt7R0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b-Zw_CNsI1b",
        "outputId": "24f222f9-bef9-4670-f859-5352cb649d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 1 before receiving has the number 0.0\n",
            "Process 1 after generating sample 0.41413092935852913\n",
            "Process 0 drew the number 0.24738626081378612\n",
            "Process 1 received the number 0.24738626081378612\n",
            "Process 1 has max value  0.41413092935852913\n",
            "Process 0 has max value  0.41413092935852913\n"
          ]
        }
      ],
      "source": [
        "!mpiexec --allow-run-as-root --oversubscribe -n 2 python question-2-mpi.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfiAFrTLrm6H"
      },
      "source": [
        "##Question 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_ZwiWRbsOxz",
        "outputId": "fb8c1562-2813-4f60-a99a-8090df6ade83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing question-3-mpi.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile question-3-mpi.py\n",
        "\n",
        "import numpy\n",
        "from mpi4py import MPI\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "\n",
        "\n",
        "randNum = numpy.zeros(1)\n",
        "randNum[0] = numpy.random.random_sample(1)\n",
        "print(\"Process\", rank, \"drew the number\", randNum[0])\n",
        "\n",
        "biggest_num = numpy.zeros(1)\n",
        "comm.Reduce(randNum, biggest_num, MPI.MAX, root=0)\n",
        "\n",
        "if rank == 0:\n",
        "  print(\"Process 0 has max value\", biggest_num[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Q3 (testing with 8 processes), we expect the following cell output to be in the form:\n",
        "\n",
        "```\n",
        "Process 3 drew the number 0.644414619435742\n",
        "Process 7 drew the number 0.3318780441129008\n",
        "Process 1 drew the number 0.30690199619345326\n",
        "Process 2 drew the number 0.3000357589861674\n",
        "Process 0 drew the number 0.37527495488187257\n",
        "Process 4 drew the number 0.5049044705082459\n",
        "Process 5 drew the number 0.748826873661416\n",
        "Process 6 drew the number 0.44233981192412875\n",
        "Process 0 has max value 0.748826873661416\n",
        "```\n",
        "\n",
        "(but with different numbers).\n",
        "\n"
      ],
      "metadata": {
        "id": "35DSopqPvdX8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99wJMqFdsRKs",
        "outputId": "cf8342ba-8ea3-4163-d32f-c799c7bf9846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 2 drew the number 0.9245021132194493\n",
            "Process 4 drew the number 0.8818087550614695\n",
            "Process 6 drew the number 0.4745548146077062\n",
            "Process 7 drew the number 0.537542247783074\n",
            "Process 1 drew the number 0.6301321746331191\n",
            "Process 3 drew the number 0.1070882009157611\n",
            "Process 5 drew the number 0.06609820483048212\n",
            "Process 0 drew the number 0.11515836166450777\n",
            "Process 0 has max value 0.9245021132194493\n"
          ]
        }
      ],
      "source": [
        "!mpiexec --allow-run-as-root --oversubscribe -n 8 python question-3-mpi.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ur8NQ9cEXIM"
      },
      "source": [
        "##Question 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45K9YtTUEYji",
        "outputId": "9f5dd73b-7f73-4102-c329-50699f0d6239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing question-4-mpi.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile question-4-mpi.py\n",
        "\n",
        "import numpy\n",
        "from mpi4py import MPI\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "\n",
        "## YOUR CODE HERE\n",
        "status = MPI.Status()\n",
        "randNum = numpy.zeros(1)\n",
        "randNum[0] = numpy.random.random_sample(1)\n",
        "print(\"Process\", rank, \"drew the number\", randNum[0])\n",
        "\n",
        "if rank == 0:\n",
        "    size = comm.Get_size()\n",
        "    biggestNum = randNum  # Reuse this memory\n",
        "    biggestSrc = 0\n",
        "    incomingNum = numpy.zeros(1)\n",
        "    for _ in range(1, size): # we ignore ourselves\n",
        "        comm.Recv(incomingNum, source=MPI.ANY_SOURCE, status=status)\n",
        "        if incomingNum[0] > biggestNum[0]:\n",
        "            biggestNum[0] = incomingNum[0]\n",
        "            biggestSrc = status.source\n",
        "    print(\"Process 0 has max value\", biggestNum[0], \"found at rank\", biggestSrc)\n",
        "else:\n",
        "    comm.Send(randNum, dest=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Q4, we expect the following cell output to be in the form:\n",
        "\n",
        "\n",
        "```\n",
        "Process 0 drew the number 0.11288481815163798\n",
        "Process 4 drew the number 0.060721653476019655\n",
        "Process 3 drew the number 0.13311050208290287\n",
        "Process 6 drew the number 0.6279276536062464\n",
        "Process 5 drew the number 0.7787862146779945\n",
        "Process 1 drew the number 0.17355707061903436\n",
        "Process 2 drew the number 0.3926657952242526\n",
        "Process 7 drew the number 0.3321183350590743\n",
        "Process 0 max random number 0.7787862146779945 found at rank 5\n",
        "\n",
        "```\n",
        "(but with different numbers)\n"
      ],
      "metadata": {
        "id": "KZOHvhRZwtJV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j-M5TAJEcRE",
        "outputId": "8691a10a-f6e5-48b7-a4fa-0bc3c3665008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 1 drew the number 0.7469798203733721\n",
            "Process 5 drew the number 0.3537527017320806\n",
            "Process 7 drew the number 0.5703982293721145\n",
            "Process 2 drew the number 0.6355981660123224\n",
            "Process 0 drew the number 0.2610898513192419\n",
            "Process 4 drew the number 0.8242023603834463\n",
            "Process 6 drew the number 0.9522024035682978\n",
            "Process 3 drew the number 0.22808189768112908\n",
            "Process 0 has max value 0.9522024035682978 found at rank 6\n"
          ]
        }
      ],
      "source": [
        "!mpiexec --allow-run-as-root --oversubscribe -n 8 python question-4-mpi.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4yVYviJjIn8"
      },
      "source": [
        "#Part B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrQB4SqgSbL6"
      },
      "source": [
        "##Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHC1qQm9dBrJ"
      },
      "source": [
        "before jit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4L800VL9imd",
        "outputId": "273c178b-91a8-4c2b-ab73-4405461ecc23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import numba\n",
        "from numba import jit\n",
        "\n",
        "def extract_bit(n, i):\n",
        "  return n >> i & 1 == 1\n",
        "\n",
        "print(extract_bit(0b1101, 0))\n",
        "print(extract_bit(0b1101, 1))\n",
        "print(extract_bit(0b1101, 2))\n",
        "print(extract_bit(0b1101, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dvvvfLJx9qhh"
      },
      "outputs": [],
      "source": [
        "def check_circuit(start, end):\n",
        "  v = np.ones(32, dtype=np.int32)\n",
        "  count = 0\n",
        "  for bits in range(start, end):\n",
        "    for i in range(32):\n",
        "      v[i] = extract_bit(bits, i)\n",
        "\n",
        "    if (((v[0] or v[1]) and (not v[1] or not v[3]) and (v[2] or v[3])\n",
        "       and (not v[3] or not v[4]) and (v[4] or not v[5])\n",
        "       and (v[5] or not v[6]) and (v[5] or v[6])\n",
        "       and (v[6] or not v[15]) and (v[7] or not v[8])\n",
        "       and (not v[7] or not v[13]) and (v[8] or v[9])\n",
        "       and (v[8] or not v[9]) and (not v[9] or not v[10])\n",
        "       and (v[9] or v[11]) and (v[10] or v[11])\n",
        "       and (v[12] or v[13]) and (v[13] or not v[14])\n",
        "       and (v[14] or v[15]))\n",
        "       and\n",
        "          ( (v[16] or v[17]) and (not v[17] or not v[19]) and (v[18] or v[19])\n",
        "       and (not v[19] or not v[20]) and (v[20] or not v[21])\n",
        "       and (v[21] or not v[22]) and (v[21] or v[22])\n",
        "       and (v[22] or not v[31]) and (v[23] or not v[24])\n",
        "       and (not v[23] or not v[29]) and (v[24] or v[25])\n",
        "       and (v[24] or not v[25]) and (not v[25] or not v[26])\n",
        "       and (v[25] or v[27]) and (v[26] or v[27])\n",
        "       and (v[28] or v[29]) and (v[29] or not v[30])\n",
        "       and (v[30] or v[31]))):\n",
        "      count += 1\n",
        "  return count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zvb-QzPRf0l",
        "outputId": "f6f44e1d-96fc-431b-9a95-305eaf049cc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "CPU times: user 10.8 s, sys: 26.3 ms, total: 10.8 s\n",
            "Wall time: 11.8 s\n"
          ]
        }
      ],
      "source": [
        "%time print(check_circuit(0, 1048576))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9TyFZ1wdFvR"
      },
      "source": [
        "after jit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AACSsqPYJP6z"
      },
      "outputs": [],
      "source": [
        "from numba import jit\n",
        "\n",
        "@jit\n",
        "def extract_bit_jit(n, i):\n",
        "  return n >> i & 1 == 1\n",
        "\n",
        "@jit\n",
        "def check_circuit_jit(start, end):\n",
        "  v = np.ones(32, dtype=np.int32)\n",
        "  count = 0\n",
        "  for bits in range(start, end):\n",
        "    for i in range(32):\n",
        "      # Calling the extract_bit function was causing warnings & causing massive slowdown\n",
        "      # v[i] = extract_bit_jit(bits, i)\n",
        "      v[i] = (bits >> i & 1 == 1)\n",
        "\n",
        "    if (((v[0] or v[1]) and (not v[1] or not v[3]) and (v[2] or v[3])\n",
        "       and (not v[3] or not v[4]) and (v[4] or not v[5])\n",
        "       and (v[5] or not v[6]) and (v[5] or v[6])\n",
        "       and (v[6] or not v[15]) and (v[7] or not v[8])\n",
        "       and (not v[7] or not v[13]) and (v[8] or v[9])\n",
        "       and (v[8] or not v[9]) and (not v[9] or not v[10])\n",
        "       and (v[9] or v[11]) and (v[10] or v[11])\n",
        "       and (v[12] or v[13]) and (v[13] or not v[14])\n",
        "       and (v[14] or v[15]))\n",
        "       and\n",
        "          ( (v[16] or v[17]) and (not v[17] or not v[19]) and (v[18] or v[19])\n",
        "       and (not v[19] or not v[20]) and (v[20] or not v[21])\n",
        "       and (v[21] or not v[22]) and (v[21] or v[22])\n",
        "       and (v[22] or not v[31]) and (v[23] or not v[24])\n",
        "       and (not v[23] or not v[29]) and (v[24] or v[25])\n",
        "       and (v[24] or not v[25]) and (not v[25] or not v[26])\n",
        "       and (v[25] or v[27]) and (v[26] or v[27])\n",
        "       and (v[28] or v[29]) and (v[29] or not v[30])\n",
        "       and (v[30] or v[31]))):\n",
        "      count += 1\n",
        "  return count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wAXG-boBJYAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ee8111-4505-4812-86ed-9a460cc507ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "CPU times: user 35 ms, sys: 0 ns, total: 35 ms\n",
            "Wall time: 36.5 ms\n",
            "81\n",
            "CPU times: user 2min 9s, sys: 398 ms, total: 2min 10s\n",
            "Wall time: 2min 11s\n"
          ]
        }
      ],
      "source": [
        "%time print(check_circuit_jit(0, 1048576)) # notice the function name change here\n",
        "%time print(check_circuit_jit(0, 4294967296)) # full 32-bit test.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emHdnbLeSdj7"
      },
      "source": [
        "##Question 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jw4pMoGwSeyS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['NUMBAPRO_NVVM']='/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so'  \n",
        "os.environ['NUMBAPRO_LIBDEVICE']='/usr/local/cuda-10.0/nvvm/libdevice'\n",
        "\n",
        "import numpy as np\n",
        "import numba\n",
        "from numba import cuda, jit\n",
        "\n",
        "@jit\n",
        "def extract_bit_jit(n, i):\n",
        "    return n >> i & 1 == 1\n",
        "\n",
        "@cuda.jit\n",
        "def check_circuit_gpu(start, end, count_out):\n",
        "  id = cuda.grid(1)\n",
        "  per = (end - start) // cuda.gridsize(1)\n",
        "  thread_start = id * per\n",
        "  thread_end = (id+1) * per\n",
        "\n",
        "  v = cuda.local.array(32, dtype=numba.int32)\n",
        "  count = 0\n",
        "  for bits in range(thread_start, thread_end):\n",
        "    for i in range(32):\n",
        "        # Calling the extract_bit function was causing warnings\n",
        "        v[i] = (bits >> i & 1 == 1)\n",
        "\n",
        "        if (((v[0] or v[1]) and (not v[1] or not v[3]) and (v[2] or v[3])\n",
        "          and (not v[3] or not v[4]) and (v[4] or not v[5])\n",
        "          and (v[5] or not v[6]) and (v[5] or v[6])\n",
        "          and (v[6] or not v[15]) and (v[7] or not v[8])\n",
        "          and (not v[7] or not v[13]) and (v[8] or v[9])\n",
        "          and (v[8] or not v[9]) and (not v[9] or not v[10])\n",
        "          and (v[9] or v[11]) and (v[10] or v[11])\n",
        "          and (v[12] or v[13]) and (v[13] or not v[14])\n",
        "          and (v[14] or v[15]))\n",
        "          and\n",
        "              ( (v[16] or v[17]) and (not v[17] or not v[19]) and (v[18] or v[19])\n",
        "          and (not v[19] or not v[20]) and (v[20] or not v[21])\n",
        "          and (v[21] or not v[22]) and (v[21] or v[22])\n",
        "          and (v[22] or not v[31]) and (v[23] or not v[24])\n",
        "          and (not v[23] or not v[29]) and (v[24] or v[25])\n",
        "          and (v[24] or not v[25]) and (not v[25] or not v[26])\n",
        "          and (v[25] or v[27]) and (v[26] or v[27])\n",
        "          and (v[28] or v[29]) and (v[29] or not v[30])\n",
        "          and (v[30] or v[31]))):\n",
        "            count += 1\n",
        "  cuda.atomic.add(count_out, 0, count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_i_rVos5zVDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36411849-9a1c-4260-9e67-ce70781a9997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2592] solutions\n",
            "CPU times: user 2.8 s, sys: 3.01 ms, total: 2.8 s\n",
            "Wall time: 2.8 s\n"
          ]
        }
      ],
      "source": [
        "# part b\n",
        "#16384 threads should take around 52 ms, 1 will take ~5 minutes\n",
        "count_out = cuda.to_device(np.zeros(shape=1, dtype=np.int32))\n",
        "check_circuit_gpu[128, 128](0, 4294967296, count_out)\n",
        "%time print(count_out.copy_to_host(), 'solutions')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "E7BZzfJPbNgY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5ed766-5931-41a2-f1c1-e328edc2e82d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 128:]\n",
            "[2592] solutions\n",
            "CPU times: user 2min 7s, sys: 107 ms, total: 2min 7s\n",
            "Wall time: 2min 8s\n",
            "\n",
            "[8, 128:]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 8 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2592] solutions\n",
            "CPU times: user 15.9 s, sys: 14 ms, total: 15.9 s\n",
            "Wall time: 15.9 s\n",
            "\n",
            "[16, 128:]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 16 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2592] solutions\n",
            "CPU times: user 8 s, sys: 6 ms, total: 8.01 s\n",
            "Wall time: 7.98 s\n",
            "\n",
            "[32, 128:]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 32 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2592] solutions\n",
            "CPU times: user 3.98 s, sys: 5.97 ms, total: 3.99 s\n",
            "Wall time: 4 s\n",
            "\n",
            "[64, 128:]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 64 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2592] solutions\n",
            "CPU times: user 2.92 s, sys: 1.99 ms, total: 2.92 s\n",
            "Wall time: 2.91 s\n",
            "\n",
            "[128, 128:]\n",
            "[2592] solutions\n",
            "CPU times: user 2.76 s, sys: 3.01 ms, total: 2.76 s\n",
            "Wall time: 2.75 s\n",
            "\n",
            "[256, 128:]\n",
            "[2592] solutions\n",
            "CPU times: user 2.38 s, sys: 993 µs, total: 2.38 s\n",
            "Wall time: 2.37 s\n",
            "\n",
            "[512, 128:]\n",
            "[2592] solutions\n",
            "CPU times: user 2.16 s, sys: 2 ms, total: 2.16 s\n",
            "Wall time: 2.16 s\n",
            "\n",
            "[1024, 128:]\n",
            "[2592] solutions\n",
            "CPU times: user 2.12 s, sys: 0 ns, total: 2.12 s\n",
            "Wall time: 2.14 s\n",
            "\n",
            "[2048, 128:]\n",
            "[2592] solutions\n",
            "CPU times: user 2.13 s, sys: 1.96 ms, total: 2.13 s\n",
            "Wall time: 2.13 s\n",
            "\n",
            "[4096, 128:]\n",
            "[2592] solutions\n",
            "CPU times: user 2.11 s, sys: 1.01 ms, total: 2.11 s\n",
            "Wall time: 2.1 s\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#part c\n",
        "## YOUR CODE HERE\n",
        "for n in [1,8,16,32,64,128,256,512,1024,2048,4096]:\n",
        "  count_out = cuda.to_device(np.zeros(shape=1, dtype=np.int32))\n",
        "  check_circuit_gpu[n, 128](0, 4294967296, count_out)\n",
        "  print(f\"[{n}, 128:]\")\n",
        "  %time print(count_out.copy_to_host(), 'solutions')\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuyzj7QHzYhZ"
      },
      "source": [
        "##Question 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "39JkV2Nkzacr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4461e827-12f5-485b-bae7-42c7a9f071b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assertions passed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import numba\n",
        "from numba import cuda, jit\n",
        "import os\n",
        "os.environ['NUMBAPRO_NVVM']='/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so'  \n",
        "os.environ['NUMBAPRO_LIBDEVICE']='/usr/local/cuda-10.0/nvvm/libdevice'\n",
        "\n",
        "@jit\n",
        "def median(a, b, c):\n",
        "  if a > b:\n",
        "    if b > c:\n",
        "      return b \n",
        "    elif a > c: \n",
        "      return c \n",
        "    else:\n",
        "      return a  \n",
        "  else: \n",
        "    if a > c:\n",
        "      return a\n",
        "    elif b > c:\n",
        "      return c\n",
        "    else:\n",
        "      return b \n",
        "\n",
        "@jit\n",
        "def median_filter_seq(A):\n",
        "  n = np.shape(A)[0]\n",
        "  r = np.zeros(n, dtype=np.uint8)\n",
        "  r[0] = A[0]\n",
        "  r[n-1] = A[n-1]\n",
        "  \n",
        "  for i in range(1,n-1):\n",
        "    r[i] = median(A[i-1], A[i], A[i+1])\n",
        "  \n",
        "  return r\n",
        "\n",
        "A = np.random.randint(256, size=256, dtype=np.uint8)\n",
        "B = np.array([1, 5, 3, 4, 2, 9, 4])\n",
        "\n",
        "A_seq = median_filter_seq(A)\n",
        "B_seq = median_filter_seq(B)\n",
        "\n",
        "@cuda.jit\n",
        "def median_filter(A):\n",
        "  i = cuda.grid(1)\n",
        "  ## YOUR CODE HERE\n",
        "  if i == 0 or i == len(A) - 1:\n",
        "    return\n",
        "  prev_val = A[i-1]\n",
        "  current_val = A[i]\n",
        "  next_val = A[i+1]\n",
        "  A[i] = median(prev_val, current_val, next_val)\n",
        "\n",
        "\n",
        "\n",
        "median_filter[1,256](A)\n",
        "median_filter[1,7](B)\n",
        "\n",
        "assert np.array_equal(B, B_seq)\n",
        "assert np.array_equal(A, A_seq)\n",
        "\n",
        "print(\"Assertions passed\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}